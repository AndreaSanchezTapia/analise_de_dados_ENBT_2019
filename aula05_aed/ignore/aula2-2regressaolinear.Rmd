---
title: 'aula 2: regressão linear'
author: "Sara Mortara"
date: "4.dez.2018"
output: beamer_presentation
fonttheme: "professionalfonts"

header-includes:
  - \usepackage{longtable,booktabs}
  - \usepackage{xcolor}
  - \definecolor{cor1}{HTML}{E1BD6D}
  - \definecolor{cor2}{HTML}{EABE94}
  - \definecolor{cor3}{HTML}{0B775E}
  - \definecolor{cor4}{HTML}{35274A}
  - \definecolor{cor5}{HTML}{F2300F}
  - \setbeamercolor{title}{fg=cor3}
  - \setbeamercolor{frametitle}{fg=cor4}
  - \setbeamercolor{structure}{fg=cor5}
  - \renewcommand\alert[1]{\textcolor{cor5}{#1}}
  #- \DeclareOptionBeamer{style}{\def\beamer@mytheme@style{1}}
  #- \ExecuteOptionsBeamer{style=orange} % blue will be default if nothing is given
  #- \setbeamercolor*{title page header}{fg=orange}
  #- \def\beamer@mytheme@stylegreen{orange}%
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
# colortheme: "orange"
```

## sobre a aula

1. definição

2. estimativa de parâmetros

3. diagnóstico do modelo

4. exemplos de regressão linear

## 

\center \Huge \alert{1. definição}

```{r, preparando os dados, echo=FALSE}

# definindo diretorio de trabalho
#setwd("~/Dropbox/posdoc/disciplina_modelagem/codigos")

# carregando pacotes
library(wesanderson)
library(knitr)

cor <- wes_palette("Rushmore1") #("FantasticFox1")

# definindo diretorio de trabalho
setwd("~/Dropbox/posdoc/disciplina_modelagem/teoricas")

# regressao linear

# vamos gerar os dados 

set.seed(4)
x1 = seq(1,5, by=0.5)
y0 = 1.2 + 3.5 * x1
res = rnorm(n= 9, mean= 0, sd= 5)
y1 = y0 + res
xy=data.frame(x1, y0, res, y1)

## plot(x1, y1)
## abline(lm(y1~x1))
## summary(lm(y1~x1))

xy$lmpred <- predict(lm(y1~x1))
xy$lmres <- residuals(lm(y1~x1))
```

```{r, echo=FALSE, fig.height=4, fig.width=4, fig.align="center"}
plot(y1 ~ x1, data=xy, las=1, bty="l",cex.lab=1.5, cex.axis=1.5, cex=1,
     xaxt="n", yaxt="n",
     xlab="", ylab="", col=cor[3], pch=19)
abline(lm(y1 ~ x1), col='grey40', lwd=2)
```


## modelos lineares

\setbeamercovered{invisible}

\begin{itemize}[<+->]
\item modelo matemático com incerteza: $Y = a + bx + \epsilon$
  \item relação entre duas ou mais variáveis
  \begin{itemize}
  \item predição
  \item extrapolação
\end{itemize}
\end{itemize}

\begin{overprint}

\onslide<1,2>
```{r cars, echo = FALSE, fig.align='center', fig.width=2.5, fig.height=3}
plot(y1 ~ x1, data=xy, las=1, bty="l", cex=.7,
     xaxt="n", yaxt="n",
     xlab="", ylab="", col=cor[3], pch=19)
mtext("preditora", 1, cex=.9)
mtext("resposta", 2, cex=.9)
```
\onslide<3>
```{r, echo = FALSE, fig.align='center', fig.width=2.5, fig.height=3}
plot(y1 ~ x1, data=xy, las=1, bty="l", cex=.7,
     xaxt="n", yaxt="n",
     xlab="", ylab="", col=cor[3], pch=19)
mtext("preditora", 1, cex=.9)
mtext("resposta", 2, cex=.9)
abline(lm(y1 ~ x1), col=cor[2], lwd=3)
```

\onslide<4>
```{r, echo = FALSE, fig.align='center', fig.width=3, fig.height=3}
plot(y1 ~ x1, data=xy, las=1, bty="l", cex=.7,
     xaxt="n", yaxt="n",
     xlab="", ylab="", col=cor[3], pch=19, xlim=c(1, 10), ylim=c(3.7, 37))
mtext("preditora", 1, cex=.9)
mtext("resposta", 2, cex=.9)
segments(x0=0.7, x1=5.05, y0=4.97, y1=22.92, col=cor[2], lwd=4)
segments(x0=5.05, x1=8.80, y0=22.92, y1=37.96, col=cor[2], lwd=4, lty=2)
```

\end{overprint}

## modelo de regressão linear

\begin{center}
$ y = a + bx $

$ y = \alpha + \beta X + \epsilon $

$ \epsilon = N (0, \sigma) $ 

\end{center}

```{r, echo = FALSE, fig.align='center', fig.width=2.5, fig.height=2.8}
plot(y1 ~ x1, data=xy, las=1, bty="l", cex=.7,
     xaxt="n", yaxt="n",
     xlab="", ylab="", col=cor[3], pch=19)
mtext("preditora", 1, cex=.7)
mtext("resposta", 2, cex=.7)
abline(lm(y1 ~ x1), col=cor[2], lwd=3)
```


## fórmula do modelo linear no R

variável resposta $\sim$ variável preditora

\alert{equação} | \alert{fórmula no R}
------|------
$y = a + bx$ | $y \sim x$
$y = a + bx + cz$ | $y \sim x + z$


## entendendo a regressão passo a passo

\center
![](figuras/stairs.jpg){width=60%}

## variável resposta é normal?

\center
```{r, echo=FALSE, fig.width=3, fig.height=3.2}
hist(y1, probability = TRUE, ylab="densidade", col=cor[3], main="", border="grey20")
```

## variável resposta é normal?

\center
```{r, echo=FALSE, fig.width=3, fig.height=3.2}
hist(y1, probability = TRUE, ylab="densidade", col=cor[3], main="", border="grey20")
curve(dnorm(x, mean(y1), sd(y1)), add=TRUE, lwd=3, col=cor[2])
```

## qual a relação entre a variável preditora e a resposta?

```{r, echo = FALSE, fig.align='center', fig.width=3, fig.height=3.3}
plot(y1 ~ x1, data=xy, las=1, bty="l", cex=.7,
     xaxt="n", yaxt="n",
     xlab="", ylab="", col=cor[3], pch=19)
mtext("preditora", 1, cex=.7)
mtext("resposta", 2, cex=.7)
#abline(lm(y1 ~ x1), col=cor[2], lwd=3)
```

## 

\center \Huge \alert{2. estimativa dos parâmetros}

\includegraphics{figuras/parametros.png}

## estimativa dos parâmetros

\begin{itemize}
\item mínimos quadrados
\item máxima verossimilhança
\end{itemize}

## mínimos quadrados

\begin{overprint}

\onslide<1>
```{r, echo = FALSE, fig.align='center', fig.width=3, fig.height=3.3}
plot(y1 ~ x1, data=xy, las=1, bty="l", cex=.7,
     #xaxt="n", yaxt="n",
     xlab="preditora", ylab="resposta", col=cor[3], pch=19)
#abline(lm(y1 ~ x1), col=cor[2], lwd=3)
points(x=mean(x1), y=mean(y1), pch=19, cex=.6)
points(x=mean(x1), y=mean(y1), pch=1, cex=1.2)
text("fulcro", x=mean(x1)+.37, y=mean(y1), cex=.4)
```

\onslide<2>
```{r, echo = FALSE, fig.align='center', fig.width=3, fig.height=3.3}
plot(y1 ~ x1, data=xy, las=1, bty="l", cex=.7,
     #xaxt="n", yaxt="n",
     xlab="preditora", ylab="resposta", col=cor[3], pch=19)
#abline(lm(y1 ~ x1), col=cor[2], lwd=3)
points(x=mean(x1), y=mean(y1), pch=19, cex=.6)
points(x=mean(x1), y=mean(y1), pch=1, cex=1.2)
abline(a=16.8 , b=-1)
```

\onslide<3>
```{r, echo = FALSE, fig.align='center', fig.width=3, fig.height=3.3}
plot(y1 ~ x1, data=xy, las=1, bty="l", cex=.7,
     #xaxt="n", yaxt="n",
     xlab="preditora", ylab="resposta", col=cor[3], pch=19)
#abline(lm(y1 ~ x1), col=cor[2], lwd=3)
points(x=mean(x1), y=mean(y1), pch=19, cex=.6)
points(x=mean(x1), y=mean(y1), pch=1, cex=1.2)
abline(a=-10 , b=8.07)
```

\onslide<4>
```{r, echo = FALSE, fig.align='center', fig.width=3, fig.height=3.3}
plot(y1 ~ x1, data=xy, las=1, bty="l", cex=.7,
     #xaxt="n", yaxt="n",
     xlab="preditora", ylab="resposta", col=cor[3], pch=19)
#abline(lm(y1 ~ x1), col=cor[2], lwd=3)
points(x=mean(x1), y=mean(y1), pch=19, cex=.6)
points(x=mean(x1), y=mean(y1), pch=1, cex=1.2)
abline(lm(y1 ~ x1))
```

\end{overprint}


## estimativa dos parâmetros

\center $y = 1.63 + 4.08x$ 

```{r, echo = FALSE, fig.align='center', fig.width=3, fig.height=3.3}
prev <- predict(lm(y1 ~ x1))
plot(y1 ~ x1, data=xy, las=1, bty="l", cex=.7,
     #xaxt="n", yaxt="n",
     xlab="preditora", ylab="resposta", col=cor[3], pch=19)
#abline(lm(y1 ~ x1), col=cor[2], lwd=3)
points(x=mean(x1), y=mean(y1), pch=19, cex=.6)
points(x=mean(x1), y=mean(y1), pch=1, cex=1.2)
segments(x0=x1, x1=x1, y0=y1, y1=prev, lty=2)
points(y1 ~ x1, data=xy, las=1, bty="l", cex=.7, col=cor[3], pch=19)
abline(lm(y1 ~ x1), col=cor[2], lwd=2)
```

## modelo linear no R

\footnotesize
```{r, echo=FALSE}
mod <- lm(y1 ~ x1)
summary(mod)
```


## incerteza na estimativa

\center $y = 1.63 + 4.08x + \epsilon$ 


\flushleft \alert{estimativa dos coeficientes}

```{r, echo=FALSE}
coef(mod)
```


\flushleft \alert{intervalo de confiança}


```{r, echo=FALSE}
confint(mod)
```

## resíduo do modelo linear

```{r, echo = FALSE, fig.align='center', fig.width=3, fig.height=3.3}
plot(y1 ~ x1, data=xy, las=1, bty="l", cex=.7, col=cor[3],
     #xaxt="n", yaxt="n",
     xlab="preditora", ylab="resposta", pch=19)
segments(x0=x1, x1=x1, y0=y1, y1=prev, lty=2)
points(y1 ~ x1, data=xy, las=1, bty="l", cex=.7, pch=19, col=cor[3])
abline(lm(y1 ~ x1), lwd=2, col=cor[2])
```

## partição da variância do modelo linear

\center

\alert{desvio quadrático do modelo linear}

$SQ_{total} = SQ_{mod} + SQ_{erro}$ 

## desvio quadrático total

$$ SQ_{total} = \sum_{i=1}^n (y_{i} - \bar{y})^2$$

```{r, echo = FALSE, fig.align='center', fig.width=3, fig.height=3.3}
plot(y1 ~ x1, data=xy, las=1, bty="l", cex=.7, col=cor[3],
     #xaxt="n", yaxt="n",
     xlab="preditora", ylab="resposta", pch=19)
abline(h=mean(y1), col=cor[2], lwd=2)
segments(x0=x1, x1=x1, y0=y1, y1=mean(y1), lty=2)
points(y1 ~ x1, data=xy, las=1, bty="l", cex=.7, pch=19, col=cor[3])
#abline(lm(y1 ~ x1), lwd=2, col='grey30')
```


## desvio quadrático total

$$ SQ_{total} = \sum_{i=1}^n (y_{i} - \bar{y})^2$$

```{r, echo=FALSE, fig.width=4}
dev <- (y1 - mean(y1))^2
devtot <- sum(dev)
tab.dev <-  data.frame(x1, y1, y_medio=mean(y1), dif_yi_y=y1 - mean(y1), 
                       desvio=dev)
sq.tot <- round(sum(dev),2)
kable(round(tab.dev, 2))
```   

\center $SQ_{total} = `r sq.tot`$ 

## desvio quadrático do resíduo

\center $$ SQ_{erro} = \sum_{i=1}^n (y_{i} - \hat{y}_i)^2$$

```{r, echo = FALSE, fig.align='center', fig.width=3, fig.height=3.3}
plot(y1 ~ x1, data=xy, las=1, bty="l", cex=.7, col=cor[3],
     #xaxt="n", yaxt="n",
     xlab="preditora", ylab="resposta", pch=19)
abline(mod, col=cor[2], lwd=2)
segments(x0=x1, x1=x1, y0=y1, y1=prev, lty=2)
points(y1 ~ x1, data=xy, las=1, bty="l", cex=.7, pch=19, col=cor[3])
#abline(lm(y1 ~ x1), lwd=2, col='grey30')
```


## desvio quadrático do resíduo

\center $$ SQ_{erro} = \sum_{i=1}^n (y_{i} - \hat{y}_i)^2$$

```{r, echo=FALSE, fig.width=4}
devres <- residuals(mod)^2
tab.devres <- data.frame(x1, y1, residuo=residuals(mod), desvio=devres)
kable(round(tab.devres, 2))
sq.er <- round(sum(devres),2)
sq.mod <- sq.tot-sq.er
```   

\center $SQ_{erro} = `r sq.er`$

## desvio quadrático do modelo

\center 

$SQ_{total} = SQ_{mod} + SQ_{erro}$ 

$SQ_{mod} = SQ_{total} - SQ_{erro}$

$SQ_{mod} = `r sq.tot` - `r sq.er`$

$SQ_{mod} = `r sq.tot-sq.er`$

## partição da variância do modelo

\center
$SQ_{total} = `r sq.tot`$

$SQ_{mod} = `r sq.mod`$

$SQ_{erro} = `r sq.er`$


\flushleft \alert{tabela de anova}

\footnotesize 

```{r}
anova(mod)
```

## coeficiente de determinação, o $R^{2}$

\center 
$R^2 = \frac{SQ_{mod}}{SQ_total}$

$R^2 = \frac{`r sq.mod`}{`r sq.tot`}$

$R^2 = `r round(sq.mod/sq.tot, 4)`$

## coeficiente de determinação, o $R^{2}$ 

\footnotesize
```{r}
summary(mod)
```

## 

\center \Huge \alert{2. diagnóstico do modelo}

\includegraphics{figuras/diagnostico.jpg}


## diagnóstico do modelo: o resíduo

```{r}
par(mfrow=c(1,2))
hist(residuals(mod), main="", probability=TRUE, col=cor[3], xlab="resíduo", ylab="densidade")
boxplot(residuals(mod), ylab="resíduo")
```

## diagnóstico do modelo: o resíduo


```{r, fig.width=8, fig.height=8, fig.align='center'}
par(mfrow=c(2,2))
plot(mod)
```

## resíduos vs valores preditos

\includegraphics{figuras/diagnostics1.jpeg}


## qráfico QQ

\includegraphics{figuras/diagnostics2.jpeg}


## dispersão dos resíduos

\includegraphics{figuras/diagnostics3.jpeg}


## resíduos vs influência (alavanca)

\includegraphics{figuras/diagnostics5.jpeg}


## dado: o melhor diagnóstico do modelo

```{r, echo = FALSE, fig.align='center', fig.width=3, fig.height=3.3}
plot(y1 ~ x1, data=xy, las=1, bty="l", cex=.7, col=cor[3],
     #xaxt="n", yaxt="n",
     xlab="preditora", ylab="resposta", pch=19)
abline(lm(y1 ~ x1), lwd=2, col=cor[2])
```

## 

\Huge \center \alert{4. exemplos de regressão linear}

## dieta da lagarta

\includegraphics{figuras/lagarta.jpg}

## compostos químicos da folha afetam o crescimento de lagartas?

\pause \alert{contexto teórico:} Compostos taninos podem defender as folhas contra insetos herbíboros

\pause \alert{hipótese:} Toxicidade do tanino na folha diminui o crescimento de lagartas

\pause \alert{previsão:} Lagartas que consomem folhas com maior quantidade de tanino irão crescer menos

```{r, echo=FALSE, fig.align='center', fig.width=3, fig.height=3}
lag <- read.table("../codigos/dados_crawley/regression.txt", header=TRUE)
mod.lag <- lm(growth ~ tannin, data=lag)
plot(growth ~ tannin, data=lag, col="white", xaxt="n", yaxt="n", bty='l', xlab="", ylab="")
mtext("quantidade de tanino", 1)
mtext("crescimento", 2)
abline(mod.lag, col=cor[3], lwd=2)
```

## experimento: crescimento de lagartas com dieta variando a quantidade de tanino

\pause \alert{variável resposta:} crescimento

```{r, fig.width=3, fig.height=3}
boxplot(lag$growth, col=cor[3])
```

\pause \alert{variável preditora:} quantidade de tanino

 0 1 2 3 4 5 6 7 8

## ajustando o modelo linear aos dados

\footnotesize
```{r, echo=TRUE}
# lendo os dados e gravando no objeto lag
lag <- read.table("../codigos/dados_crawley/regression.txt", 
                  header=TRUE)
# ajustando o modelo linear entre crescimento e tanino
mod.lag <- lm(growth ~ tannin, data=lag)
```

## sumário do modelo

\footnotesize
```{r}
# checando o sumário do modelo
summary(mod.lag)
```

## ajuste do modelo aos dados

```{r, echo=FALSE, fig.align='center', fig.width=3, fig.height=3}
plot(growth ~ tannin, data=lag, bty='l', xlab="quantidade de tanino", 
     ylab="crescimento", col=cor[4], pch=19)
abline(mod.lag, col=cor[1], lwd=2)
```

## diagnóstico do modelo

```{r, echo=FALSE, fig.align='center', fig.width=8, fig.height=8}
par(mfrow=c(2,2))
plot(mod.lag)
par(mfrow=c(1,1))
```

## salário & gênero

\includegraphics{figuras/gender_gap.jpg}

## desigualdade salarial entre os sexos

\pause \alert{contexto teórico:} situação da mulher na sociedade; mulheres conquistaram o mercado de trabalho mais tardiamente que homens

\pause \alert{hipótese:} homens recebem mais do que mulheres 

\pause \alert{previsão:} mulheres com mesma experiência que homens recebem menor salário

```{r, echo=FALSE, fig.align='center', fig.width=3, fig.height=3}
salario.m <- round(rnorm(30, mean=2000, sd=200), 0)
salario.h <- round(rnorm(30, mean=2700, sd=200), 0)
sal <- data.frame(salario=c(salario.h, salario.m), sexo=rep(c("H", "M"), each=30))

barplot(c(10, 5), ylim=c(0,13), col=c(cor[2],cor[4]), yaxt="n")
mtext("salário", 2)
mtext("sexo", 1)
legend("topright", c("homem", 'mulher'), pch=15, col=c(cor[2], cor[4]), bty='n', cex=.7)
arrows(x0=c(.7,1.9), x1=c(.7,1.9), y0=c(10,5), y1=c(12, 7), length = .1, angle=90)
```

## amostragem: salário de homens e mulheres em diferentes empresas de tecnologia

\pause \alert{variável resposta:} salário

```{r, fig.width=3, fig.height=3}
boxplot(sal$salario, col=cor[3])
```

\pause \alert{variavel preditora:} gênero

2 categorias: homens e mulheres

## ajustando o modelo linear aos dados

```{r, echo=TRUE}
# ajustando o modelo linear entre salario e sexo
mod.sal <- lm(salario ~ sexo, data=sal)
```

## sumário do modelo

\footnotesize
```{r}
summary(mod.sal)
```

## ajuste do modelo aos dados

```{r, fig.width=3.5, fig.height=3.8, fig.align='center'}
med.sal <- tapply(sal$salario, sal$sexo, mean)
sd.sal <- tapply(sal$salario, sal$sexo, sd)
pred.sal <- predict(mod.sal)
pred.med <- tapply(pred.sal, sal$sexo, mean)
barplot(med.sal, ylim=c(0,med.sal[1]+260), ylab="salário", xlab="sexo", col=cor[c(2,4)])
legend("topright", c("homem", 'mulher'), pch=15, col=c(cor[2], cor[4]), bty='n', cex=.7)
arrows(x0=c(.7,1.9), x1=c(.7,1.9), y0=med.sal, y1=med.sal+sd.sal, length = .1, angle=90)
points(pred.med ~ c(.7, 1.9), pch=19, col=cor[5])
```


## diagnóstico do modelo

```{r, fig.align='center', fig.width=8, fig.height=8}
par(mfrow=c(2,2))
plot(mod.sal)
par(mfrow=c(1,1))
```




